---
id: "google-agent-day4"
topic:
  zh: "智能体评估"
  en: "Agent Evaluation"
category: "Quality"
icon: "FaChartLine"
summary:
  zh: "第四天：超越简单指标，实现全面的智能体评估"
  en: "Day 4: Moving beyond simple metrics to comprehensive Agent Eval."
details: 
  - "LLM 作为评判者 / LLM as a Judge"
  - "轨迹分析 / Trajectory Analysis"
  - "黄金数据集 / Golden Datasets"
  - "人在回路测试 / Human-in-the-loop Testing"
link: "https://www.kaggle.com/whitepaper-day4"
date: "2025-12-31"
---

# Day 4: Agent Quality and Evaluation

## Why is it hard?
Agents are non-deterministic. "Correctness" is subjective.

## Evaluation Frameworks
- **LLM as a Judge**: Using a stronger model to grade the agent's output.
- **Trajectory Analysis**: Checking *how* the agent arrived at the answer, not just the answer itself.
- **Specific Metrics**: Faithfulness, Answer Relevance, Context Recall.
